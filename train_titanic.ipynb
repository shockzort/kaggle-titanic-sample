{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import ydf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(f\"Found YDF {ydf.__version__}\")\n",
    "\n",
    "# Загрузка данных\n",
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "train_df.head(5)\n",
    "\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if big_string.find(substring) != -1:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "# Предобработка данных\n",
    "# 1. Токенизация имён\n",
    "# 2. Извлечение номера билета, если возможно\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    def normalize_name(x):\n",
    "        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n",
    "\n",
    "    def is_int(s):\n",
    "        if s[0] in ('-', '+'):\n",
    "            return s[1:].isdigit()\n",
    "        return s.isdigit()\n",
    "\n",
    "    def ticket_number(x):\n",
    "        val = x.split(\" \")[-1]\n",
    "        return int(val) if is_int(val) else 0\n",
    "\n",
    "    def ticket_item(x):\n",
    "        items = x.split(\" \")\n",
    "        if len(items) == 1:\n",
    "            return \"NONE\"\n",
    "        return \"_\".join(items[0:-1])\n",
    "\n",
    "    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n",
    "    # df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n",
    "    # df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Обработка данных, шаг 1\n",
    "def phase1clean(df):\n",
    "    # Заменяем нули на NaN\n",
    "    df.Fare = df.Fare.map(lambda x: np.nan if x == 0 else x)\n",
    "    #df.Fare = df.Fare.replace({ 512.3292 : 7.25})\n",
    "\n",
    "    # Заменяем NaN каюты на \"Неизвестно\"\n",
    "    df.Cabin = df.Cabin.fillna('Unknown')\n",
    "\n",
    "    # Заменяем NaN цены билета на среднюю цену\n",
    "    meanFare = np.mean(df.Fare)\n",
    "    df.Fare = df.Fare.fillna(meanFare)\n",
    "\n",
    "    # Заменяем NaN Age на средний Age\n",
    "    meanAge = np.mean(df.Age)\n",
    "    df.Age = df.Age.fillna(meanAge)\n",
    "\n",
    "    # Заменяем NaN Embarked моду Embarked\n",
    "    modeEmbarked = statistics.mode(df.Embarked)[0][0]\n",
    "    df.Embarked = df.Embarked.fillna(modeEmbarked)\n",
    "\n",
    "    # Создаём столбец \"Титул\" из \"Имени\"\n",
    "    title_list = ['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n",
    "                'Dr', 'Ms', 'Mlle', 'Col', 'Capt', 'Mme', 'the Countess',\n",
    "                'Dona', 'Don', 'Jonkheer', 'Lady']\n",
    "\n",
    "    df['Title'] = df['Name'].map(lambda x: substrings_in_string(x, title_list))\n",
    "\n",
    "    normalized_titles = {\n",
    "        \"Capt\":       \"Officer\",\n",
    "        \"Col\":        \"Officer\",\n",
    "        \"Major\":      \"Officer\",\n",
    "        \"Jonkheer\":   \"Royal\",\n",
    "        \"Don\":        \"Royal\",\n",
    "        \"Sir\" :       \"Royal\",\n",
    "        \"Dr\":         \"Master\",\n",
    "        \"Rev\":        \"Master\",\n",
    "        \"the Countess\":\"Royal\",\n",
    "        \"Dona\":       \"Royal\",\n",
    "        \"Mme\":        \"Mrs\",\n",
    "        \"Mlle\":       \"Miss\",\n",
    "        \"Ms\":         \"Mrs\",\n",
    "        \"Mr\" :        \"Mr\",\n",
    "        \"Mrs\" :       \"Mrs\",\n",
    "        \"Miss\" :      \"Miss\",\n",
    "        \"Master\" :    \"Master\",\n",
    "        \"Lady\" :      \"Royal\"\n",
    "    }\n",
    "\n",
    "    # Ре-Мэппинг титулов\n",
    "    df.Title = df.Title.map(normalized_titles)\n",
    "\n",
    "    # Создаём столбец \"Палуба\" из \"Каюты\"\n",
    "    #cabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\n",
    "    #df['Deck'] = df['Cabin'].map(lambda x: substrings_in_string(x, cabin_list))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Обработка данных, шаг 2\n",
    "def phase2clean(df):\n",
    "    # Размер семью из косвенных полей\n",
    "    # df['Family_Size'] = df['SibSp'] + df['Parch']\n",
    "\n",
    "    # Цена билета\n",
    "    # df['Fare_Per_Person'] = df['Fare'] / (df['Family_Size']+1)\n",
    "\n",
    "    # Возраст * class\n",
    "    # df['Age*Class'] = df['Age'] * df['Pclass']\n",
    "\n",
    "    # Выбрасываем лишние столбцы\n",
    "    df = df.drop(['Ticket'], axis=1)\n",
    "    #df = df.drop(['Ticket_item'], axis=1)\n",
    "    #df = df.drop(['Cabin'], axis=1)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df[\"Sex\"] = le.fit_transform(df[\"Sex\"].values)\n",
    "    #df[\"Deck\"] = le.fit_transform(df[\"Deck\"].values)\n",
    "    df[\"Embarked\"] = le.fit_transform(df[\"Embarked\"].values)\n",
    "    df[\"Name\"] = le.fit_transform(df[\"Name\"].values)\n",
    "    df[\"Title\"] = le.fit_transform(df[\"Title\"].values)\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_data(train_data, test_data):\n",
    "    # Сомнительные пассажиры (nan в стоимости проезда)\n",
    "    # train_data = train_data[(train_data.PassengerId != 259) & (train_data.PassengerId != 680) & (train_data.PassengerId != 738)]\n",
    "\n",
    "    train_data = phase1clean(train_data)\n",
    "    test_data = phase1clean(test_data)\n",
    "\n",
    "    train_data = phase2clean(train_data)\n",
    "    test_data = phase2clean(test_data)\n",
    "\n",
    "    train_data.isna().sum()\n",
    "    train_data.info()\n",
    "\n",
    "    test_data.isna().sum()\n",
    "    test_data.info()\n",
    "\n",
    "    return [train_data, test_data]\n",
    "\n",
    "\n",
    "# Выбираем столбцы признаков, которые будем использорвать для обучения\n",
    "do_data_cleaning = True\n",
    "\n",
    "preprocessed_train_df = preprocess(train_df)\n",
    "preprocessed_test_df = preprocess(test_df)\n",
    "\n",
    "# Дополнительно, фильтруем данные в датасете\n",
    "if do_data_cleaning:\n",
    "    preprocessed_train_df, preprocessed_test_df = clean_data(preprocessed_train_df, preprocessed_test_df)\n",
    "\n",
    "preprocessed_train_df.head(800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Нужно ли масштабировать признаки (не всегда применимо)\n",
    "do_feature_scaling = False\n",
    "if do_feature_scaling:\n",
    "    sc_X = MinMaxScaler()\n",
    "    preprocessed_train_df = sc_X.fit_transform(preprocessed_train_df)\n",
    "    preprocessed_test_df = sc_X.transform(preprocessed_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmpl = ydf.GradientBoostedTreesLearner.hyperparameter_templates()\n",
    "\n",
    "tuner = ydf.RandomSearchTuner(num_trials=150)\n",
    "tuner.choice(\"shrinkage\", [0.325, 0.3, 0.275])\n",
    "tuner.choice(\"subsample\", [1.0, 0.95, 0.9])\n",
    "tuner.choice(\"max_depth\", [3, 4, 5, 6, 7])\n",
    "tuner.choice(\"num_candidate_attributes_ratio\", [0.425, 0.4, 0.375, 0.35])\n",
    "tuner.choice(\"num_trees\", [10, 50, 100, 300])\n",
    "\n",
    "model = ydf.GradientBoostedTreesLearner(label=\"Survived\",\n",
    "                                        #num_trees=100,\n",
    "                                        #tuner=tuner,\n",
    "                                        #max_depth=6,\n",
    "                                        #shrinkage=0.325,\n",
    "                                        #subsample=0.9,\n",
    "                                        #num_candidate_attributes_ratio=0.375,\n",
    "                                        ).train(preprocessed_train_df)\n",
    "model.describe()\n",
    "tuned_self_evaluation = model.evaluate(preprocessed_train_df)\n",
    "print(f\"Accuracy: {tuned_self_evaluation.accuracy} Loss:{tuned_self_evaluation.loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def prediction_to_kaggle_format(model, threshold=0.5):\n",
    "    proba_survive = model.predict(preprocessed_test_df)\n",
    "    return pd.DataFrame({\n",
    "        \"PassengerId\": preprocessed_test_df[\"PassengerId\"],\n",
    "        \"Survived\": (proba_survive >= threshold).astype(int)\n",
    "    })\n",
    "\n",
    "def make_submission(kaggle_predictions, sub_path):\n",
    "    path=sub_path\n",
    "    kaggle_predictions.to_csv(path, index=False)\n",
    "    print(f\"Submission exported to {path}\")\n",
    "\n",
    "kaggle_predictions = prediction_to_kaggle_format(model)\n",
    "\n",
    "sub_path = os.path.join(os.path.abspath(os.getcwd()), \"submission_def.csv\")\n",
    "\n",
    "make_submission(kaggle_predictions, sub_path)\n",
    "!head $sub_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "predictions = None\n",
    "num_predictions = 0\n",
    "ensemble_size = 100\n",
    "\n",
    "# Применение ансамбля классификаторов\n",
    "for i in range(ensemble_size):\n",
    "    print(f\"Make prediction: {i}\")\n",
    "\n",
    "    # GradientBoostedTreesModel / RandomForestModel / IsolationForestLearner\n",
    "    model = ydf.GradientBoostedTreesLearner(label=\"Survived\", honest=True, random_seed=i).train(preprocessed_train_df)\n",
    "    sub_predictions = model.predict(preprocessed_test_df)\n",
    "\n",
    "    if predictions is None:\n",
    "        predictions = sub_predictions\n",
    "    else:\n",
    "        predictions += sub_predictions\n",
    "    num_predictions += 1\n",
    "\n",
    "predictions/=num_predictions\n",
    "\n",
    "kaggle_predictions = pd.DataFrame({\n",
    "    \"PassengerId\": preprocessed_test_df[\"PassengerId\"],\n",
    "    \"Survived\": (predictions >= 0.5).astype(int)\n",
    "})\n",
    "\n",
    "sub_path = os.path.join(os.path.abspath(os.getcwd()), \"ensemble_GBTL_100_ft_clean_v3.csv\")\n",
    "make_submission(kaggle_predictions, sub_path)\n",
    "!head $sub_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
