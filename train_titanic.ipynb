{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исследование классификаторов на примере решения задачи Kaggle Titanic. Бондаренко В.А. з5130902/00201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка, предобработка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import ydf\n",
    "\n",
    "print(f\"Found YDF {ydf.__version__}\")\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "# Загрузка данных\n",
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "train_df.head(5)\n",
    "\n",
    "# Конвертация предсказаний модели в формат kaggle\n",
    "def prediction_to_kaggle_format(proba_survive, threshold=0.5):\n",
    "    return pd.DataFrame({\n",
    "        \"PassengerId\": preprocessed_val_df[\"PassengerId\"],\n",
    "        \"Survived\": (proba_survive >= threshold).astype(int)\n",
    "    })\n",
    "\n",
    "def make_submission(kaggle_predictions, sub_path):\n",
    "    path=sub_path\n",
    "    kaggle_predictions.to_csv(path, index=False)\n",
    "    print(f\"Submission exported to {path}\")\n",
    "\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if big_string.find(substring) != -1:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "# Предобработка данных\n",
    "# 1. Токенизация имён\n",
    "# 2. Извлечение номера билета, если возможно\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    def normalize_name(x):\n",
    "        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n",
    "\n",
    "    def is_int(s):\n",
    "        if s[0] in ('-', '+'):\n",
    "            return s[1:].isdigit()\n",
    "        return s.isdigit()\n",
    "\n",
    "    def ticket_number(x):\n",
    "        val = x.split(\" \")[-1]\n",
    "        return int(val) if is_int(val) else 0\n",
    "\n",
    "    def ticket_item(x):\n",
    "        items = x.split(\" \")\n",
    "        if len(items) == 1:\n",
    "            return \"NONE\"\n",
    "        return \"_\".join(items[0:-1])\n",
    "\n",
    "    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n",
    "    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n",
    "    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Обработка данных, шаг 1\n",
    "def phase1clean(df):\n",
    "    # Заменяем нули на NaN\n",
    "    df.Fare = df.Fare.map(lambda x: np.nan if x == 0 else x)\n",
    "    df.Fare = df.Fare.replace({ 512.3292 : 7.25})\n",
    "\n",
    "    # Заменяем NaN каюты на \"Неизвестно\"\n",
    "    df.Cabin = df.Cabin.fillna('Unknown')\n",
    "\n",
    "    # Заменяем NaN цены билета на среднюю цену\n",
    "    meanFare = np.mean(df.Fare)\n",
    "    df.Fare = df.Fare.fillna(meanFare)\n",
    "\n",
    "    # Заменяем NaN Age на средний Age\n",
    "    meanAge = np.mean(df.Age)\n",
    "    df.Age = df.Age.fillna(meanAge)\n",
    "\n",
    "    # Заменяем NaN Embarked моду Embarked\n",
    "    modeEmbarked = statistics.mode(df.Embarked)[0][0]\n",
    "    df.Embarked = df.Embarked.fillna(modeEmbarked)\n",
    "\n",
    "    # Создаём столбец \"Титул\" из \"Имени\"\n",
    "    title_list = ['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n",
    "                'Dr', 'Ms', 'Mlle', 'Col', 'Capt', 'Mme', 'the Countess',\n",
    "                'Dona', 'Don', 'Jonkheer', 'Lady']\n",
    "\n",
    "    df['Title'] = df['Name'].map(lambda x: substrings_in_string(x, title_list))\n",
    "\n",
    "    normalized_titles = {\n",
    "        \"Capt\":       \"Officer\",\n",
    "        \"Col\":        \"Officer\",\n",
    "        \"Major\":      \"Officer\",\n",
    "        \"Jonkheer\":   \"Royal\",\n",
    "        \"Don\":        \"Royal\",\n",
    "        \"Sir\" :       \"Royal\",\n",
    "        \"Dr\":         \"Master\",\n",
    "        \"Rev\":        \"Master\",\n",
    "        \"the Countess\":\"Royal\",\n",
    "        \"Dona\":       \"Royal\",\n",
    "        \"Mme\":        \"Mrs\",\n",
    "        \"Mlle\":       \"Miss\",\n",
    "        \"Ms\":         \"Mrs\",\n",
    "        \"Mr\" :        \"Mr\",\n",
    "        \"Mrs\" :       \"Mrs\",\n",
    "        \"Miss\" :      \"Miss\",\n",
    "        \"Master\" :    \"Master\",\n",
    "        \"Lady\" :      \"Royal\"\n",
    "    }\n",
    "\n",
    "    # Ре-Мэппинг титулов\n",
    "    df.Title = df.Title.map(normalized_titles)\n",
    "\n",
    "    # Создаём столбец \"Палуба\" из \"Каюты\"\n",
    "    cabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\n",
    "    df['Deck'] = df['Cabin'].map(lambda x: substrings_in_string(x, cabin_list))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Обработка данных, шаг 2\n",
    "def phase2clean(df):\n",
    "    # Размер семьи из косвенных полей\n",
    "    #df['Family_Size'] = df['SibSp'] + df['Parch']\n",
    "\n",
    "    # Цена билета\n",
    "    #df['Fare_Per_Person'] = df['Fare'] / (df['Family_Size']+1)\n",
    "\n",
    "    # Возраст * class\n",
    "    #df['Age*Class'] = df['Age'] * df['Pclass']\n",
    "\n",
    "    # Выбрасываем лишние столбцы\n",
    "    df = df.drop(['Ticket'], axis=1)\n",
    "    df = df.drop(['Cabin'], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_data(train_data, test_data):\n",
    "    # Сомнительные пассажиры (nan в стоимости проезда)\n",
    "    # train_data = train_data[(train_data.PassengerId != 259) & (train_data.PassengerId != 680) & (train_data.PassengerId != 738)]\n",
    "\n",
    "    train_data = phase1clean(train_data)\n",
    "    test_data = phase1clean(test_data)\n",
    "\n",
    "    train_data = phase2clean(train_data)\n",
    "    test_data = phase2clean(test_data)\n",
    "\n",
    "    train_data.isna().sum()\n",
    "    train_data.info()\n",
    "\n",
    "    test_data.isna().sum()\n",
    "    test_data.info()\n",
    "\n",
    "    return [train_data, test_data]\n",
    "\n",
    "\n",
    "# Выбираем столбцы признаков, которые будем использорвать для обучения\n",
    "do_data_cleaning = True\n",
    "\n",
    "preprocessed_train_df = preprocess(train_df)\n",
    "preprocessed_val_df = preprocess(test_df)\n",
    "\n",
    "# Дополнительно, фильтруем данные в датасете\n",
    "if do_data_cleaning:\n",
    "    preprocessed_train_df, preprocessed_val_df = clean_data(preprocessed_train_df, preprocessed_val_df)\n",
    "\n",
    "# Выведем информацию о датасете и первые 10 строк таблицы\n",
    "preprocessed_train_df.info()\n",
    "preprocessed_train_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация распределения части исходных данных в виде гистограмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Визуализируем распределение части данных в виде гистограмм\n",
    "for column in preprocessed_train_df.columns:\n",
    "    if  column == 'Name' or \\\n",
    "        column == 'PassengerId' or \\\n",
    "        column == 'Cabin' or \\\n",
    "        column == 'Ticket_item' or \\\n",
    "        column == 'Ticket_number':\n",
    "        continue\n",
    "\n",
    "    plt.hist(preprocessed_train_df[column])\n",
    "    plt.title(column)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Автоматический подбор оптимальных параметров модели при помощи RandomSearchTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "tmpl = ydf.GradientBoostedTreesLearner.hyperparameter_templates()\n",
    "\n",
    "# Автоматический подбор оптимальных параметров модели при помощи RandomSearchTuner\n",
    "tuner = ydf.RandomSearchTuner(num_trials=150)\n",
    "tuner.choice(\"shrinkage\", [0.325, 0.3, 0.275])\n",
    "tuner.choice(\"subsample\", [1.0, 0.95, 0.9])\n",
    "tuner.choice(\"max_depth\", [3, 4, 5, 6, 7])\n",
    "tuner.choice(\"num_candidate_attributes_ratio\", [0.425, 0.4, 0.375, 0.35])\n",
    "tuner.choice(\"num_trees\", [10, 50, 100, 300])\n",
    "\n",
    "model = ydf.GradientBoostedTreesLearner(label=\"Survived\",\n",
    "                                        # Такие дефолтные параметры подобрались RandomSearchTuner\n",
    "                                        # (однако генерируемые без параметров модели работают в целом лучше, при валидации на kaggle):\n",
    "                                        # num_trees=100,\n",
    "                                        # tuner=tuner,\n",
    "                                        # max_depth=6,\n",
    "                                        # shrinkage=0.325,\n",
    "                                        # subsample=0.9,\n",
    "                                        # num_candidate_attributes_ratio=0.375,\n",
    "                                        ).train(preprocessed_train_df)\n",
    "\n",
    "# Выведем характеристики полученной модели и саму модель в виде дерева\n",
    "model.describe()\n",
    "model.plot_tree()\n",
    "print(model.print_tree())\n",
    "\n",
    "tuned_self_evaluation = model.evaluate(preprocessed_train_df)\n",
    "print(f\"Accuracy: {tuned_self_evaluation.accuracy} Loss:{tuned_self_evaluation.loss}\")\n",
    "\n",
    "sub_path = os.path.join(os.path.abspath(os.getcwd()), \"finetune_GBTrees.csv\")\n",
    "make_submission(prediction_to_kaggle_format(model.predict(preprocessed_val_df)), sub_path)\n",
    "!head $sub_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение ансамбля классификаторов GradientBoostedTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "predictions = None\n",
    "num_predictions = 0\n",
    "ensemble_size = 150\n",
    "\n",
    "# Применение ансамбля классификаторов\n",
    "print(f\"Train classifier ensemble of size {ensemble_size}\")\n",
    "for i in range(ensemble_size):\n",
    "    print(f\"Make prediction: {i}\")\n",
    "\n",
    "    # Здесь можно выбрать модели\n",
    "    # GradientBoostedTreesModel / RandomForestModel / IsolationForestLearner\n",
    "    # Модель на основе GradientBoostedTrees работает лучше остальных\n",
    "    model = ydf.GradientBoostedTreesLearner(label=\"Survived\", honest=True, random_seed=i).train(preprocessed_train_df)\n",
    "    sub_predictions = model.predict(preprocessed_val_df)\n",
    "\n",
    "    if predictions is None:\n",
    "        predictions = sub_predictions\n",
    "    else:\n",
    "        predictions += sub_predictions\n",
    "    num_predictions += 1\n",
    "\n",
    "predictions/=num_predictions\n",
    "\n",
    "kaggle_predictions = pd.DataFrame({\n",
    "    \"PassengerId\": preprocessed_val_df[\"PassengerId\"],\n",
    "    \"Survived\": (predictions >= 0.5).astype(int)\n",
    "})\n",
    "\n",
    "sub_path = os.path.join(os.path.abspath(os.getcwd()), \"ensemble_GBTrees_{}.csv\".format(ensemble_size))\n",
    "make_submission(kaggle_predictions, sub_path)\n",
    "!head $sub_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование множества классификаторов и сравнение по метрикам Accuracy, R2 и F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, r2_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Попробуем применить другие модели классификаторов (не из пакета YDF)\n",
    "\n",
    "# Закодируем категориальные данные как числовые для классификаторов, которые не умеют работать с категориями\n",
    "# Получим список категориальных колонок\n",
    "s = (preprocessed_train_df.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "# Кодируем категориальные данные как числовые\n",
    "le = LabelEncoder()\n",
    "\n",
    "encoded_train = preprocessed_train_df.copy()\n",
    "encoded_val = preprocessed_val_df.copy()\n",
    "\n",
    "for column in object_cols:\n",
    "    print(f'Encoding categorical column {column}')\n",
    "    encoded_train[column] = le.fit_transform(encoded_train[column].values)\n",
    "    encoded_val[column] = le.fit_transform(encoded_val[column].values)\n",
    "\n",
    "X = encoded_train[preprocessed_val_df.columns]\n",
    "y = encoded_train['Survived']\n",
    "\n",
    "# Для проверки качества обучения классификатора требуется выполнить разбиение данных на обучающую и тестовую выборки\n",
    "# Так как для валидационной выборки kaggle отсутствует априорное знание Survived\n",
    "raw_X_train, raw_X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "\n",
    "# Нормируем признаки для улучшения сходимости обучения классификаторов\n",
    "# Также можно применять StandardScaler()\n",
    "sc_X = MinMaxScaler()\n",
    "cols = preprocessed_val_df.columns\n",
    "normalized_train_arr = sc_X.fit_transform(raw_X_train)\n",
    "normalized_test_arr = sc_X.fit_transform(raw_X_test)\n",
    "normalized_val_arr = sc_X.transform(encoded_val[cols])\n",
    "\n",
    "# 1. ydf.GradientBoostedTrees с подобранными параметрами\n",
    "train_data_for_ydf = pd.DataFrame.from_records(normalized_train_arr, columns=preprocessed_val_df.columns)\n",
    "train_data_for_ydf['Survived'] = y_train.to_numpy()\n",
    "test_data_for_ydf = pd.DataFrame.from_records(normalized_test_arr, columns=preprocessed_val_df.columns)\n",
    "test_data_for_ydf['Survived'] = y_test.to_numpy()\n",
    "\n",
    "model = ydf.GradientBoostedTreesLearner(label=\"Survived\",\n",
    "                                        num_trees=100,\n",
    "                                        max_depth=6,\n",
    "                                        shrinkage=0.325,\n",
    "                                        subsample=0.9,\n",
    "                                        num_candidate_attributes_ratio=0.375).train(train_data_for_ydf)\n",
    "ydf_single_predictions = model.predict(test_data_for_ydf)\n",
    "y_pred_ydf_single = (ydf_single_predictions >= 0.5).astype(int)\n",
    "ydf_gbt_single_acc = accuracy_score(y_test, y_pred_ydf_single)\n",
    "ydf_gbt_single_r2 = r2_score(y_test, y_pred_ydf_single)\n",
    "ydf_gbt_single_f1 = f1_score(y_test, y_pred_ydf_single)\n",
    "print('YDF GBT single, fine tuned, classification report: \\n{}'.format(classification_report(y_test, y_pred_ydf_single)))\n",
    "\n",
    "# 2. Ансамбль из ydf.GradientBoostedTrees\n",
    "ydf_ensemble_predictions = None\n",
    "num_predictions = 0\n",
    "ensemble_size = 100\n",
    "for i in range(ensemble_size):\n",
    "    model = ydf.GradientBoostedTreesLearner(label=\"Survived\", honest=True, random_seed=i).train(train_data_for_ydf)\n",
    "    sub_predictions = model.predict(test_data_for_ydf)\n",
    "\n",
    "    if ydf_ensemble_predictions is None:\n",
    "        ydf_ensemble_predictions = sub_predictions\n",
    "    else:\n",
    "        ydf_ensemble_predictions += sub_predictions\n",
    "    num_predictions += 1\n",
    "\n",
    "ydf_ensemble_predictions /= num_predictions\n",
    "\n",
    "y_pred_ydf_ensemble = (ydf_ensemble_predictions >= 0.5).astype(int)\n",
    "ydf_gbt_ensemble_acc = accuracy_score(y_test, y_pred_ydf_ensemble)\n",
    "ydf_gbt_ensemble_r2 = r2_score(y_test, y_pred_ydf_ensemble)\n",
    "ydf_gbt_ensemble_f1 = f1_score(y_test, y_pred_ydf_ensemble)\n",
    "print('YDF GBT ensemble N={}, classification report: \\n{}'.format(ensemble_size, classification_report(y_test, y_pred_ydf_ensemble)))\n",
    "\n",
    "# 3. Логистическая регрессия\n",
    "pipeline = Pipeline([('logisticregression', LogisticRegression(max_iter=100))])\n",
    "param_grid = {'logisticregression__penalty' : ['l2'],\n",
    "              'logisticregression__C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'logisticregression__solver' : ['liblinear']}\n",
    "\n",
    "# GridSearchCV подбирает параметры модели\n",
    "model = GridSearchCV(pipeline, param_grid, cv =None)\n",
    "model.fit(normalized_train_arr, y_train)\n",
    "\n",
    "y_pred_logistic_predictions = model.predict_proba(normalized_test_arr)[:,1]\n",
    "y_pred_logistic = (y_pred_logistic_predictions >= 0.5).astype(int)\n",
    "logistic_acc = accuracy_score(y_test, y_pred_logistic)\n",
    "logistic_r2 = r2_score(y_test, y_pred_logistic)\n",
    "logistic_f1 = f1_score(y_test, y_pred_logistic)\n",
    "print('Logistic regression classification report: \\n{}'.format(classification_report(y_test, y_pred_logistic)))\n",
    "\n",
    "\n",
    "# 4. RandomForestClassifier из пакета sklearn\n",
    "pipeline = Pipeline([('RandomForest', RandomForestClassifier())])\n",
    "param_grid = {\n",
    "  'RandomForest__min_samples_leaf': [1, 2, 4],\n",
    "  'RandomForest__min_samples_split': [2, 3, 4],\n",
    "  'RandomForest__n_estimators': [100, 200, 300]}\n",
    "\n",
    "model = GridSearchCV(pipeline, param_grid, cv =None)\n",
    "model.fit(normalized_train_arr, y_train)\n",
    "\n",
    "y_pred_forest_predictions = model.predict_proba(normalized_test_arr)[:,1]\n",
    "y_pred_forest = (y_pred_forest_predictions >= 0.5).astype(int)\n",
    "forest_acc = accuracy_score(y_test, y_pred_forest)\n",
    "forest_r2 = r2_score(y_test, y_pred_forest)\n",
    "forest_f1 = f1_score(y_test, y_pred_forest)\n",
    "print('RandomForest classification report: \\n{}'.format(classification_report(y_test, y_pred_forest)))\n",
    "\n",
    "# 5. XGBClassifier\n",
    "model = XGBClassifier()\n",
    "model.fit(normalized_train_arr, y_train)\n",
    "\n",
    "y_pred_XGB_predictions = model.predict_proba(normalized_test_arr)[:,1]\n",
    "y_pred_XGB = (y_pred_XGB_predictions >= 0.5).astype(int)\n",
    "XGB_acc = accuracy_score(y_test, y_pred_XGB)\n",
    "XGB_r2 = r2_score(y_test, y_pred_XGB)\n",
    "XGB_f1 = f1_score(y_test, y_pred_XGB)\n",
    "print('XGBClassifier classification report: \\n{}'.format(classification_report(y_test, y_pred_XGB)))\n",
    "\n",
    "# 6. KNN classifier\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(normalized_train_arr, y_train)\n",
    "\n",
    "y_pred_KNN_predictions = model.predict_proba(normalized_test_arr)[:,1]\n",
    "y_pred_KNN = (y_pred_KNN_predictions >= 0.5).astype(int)\n",
    "KNN_acc = accuracy_score(y_test, y_pred_KNN)\n",
    "KNN_r2 = r2_score(y_test, y_pred_KNN)\n",
    "KNN_f1 = f1_score(y_test, y_pred_KNN)\n",
    "print('KNN Classifier classification report: \\n{}'.format(classification_report(y_test, y_pred_KNN)))\n",
    "\n",
    "# 7. SVM (SVC) classifier, rbf kernel\n",
    "model = SVC(probability=True)\n",
    "model.fit(normalized_train_arr, y_train)\n",
    "\n",
    "y_pred_SVC_predictions = model.predict_proba(normalized_test_arr)[:,1]\n",
    "y_pred_SVC = (y_pred_SVC_predictions >= 0.5).astype(int)\n",
    "SVC_acc = accuracy_score(y_test, y_pred_SVC)\n",
    "SVC_r2 = r2_score(y_test, y_pred_SVC)\n",
    "SVC_f1 = f1_score(y_test, y_pred_SVC)\n",
    "print('SVC Classifier classification report: \\n{}'.format(classification_report(y_test, y_pred_SVC)))\n",
    "\n",
    "# 8. SVM (LinearSVC) classifier\n",
    "model = SVC(kernel='linear',probability=True)\n",
    "model.fit(normalized_train_arr, y_train)\n",
    "\n",
    "y_pred_LSVC_predictions = model.predict_proba(normalized_test_arr)[:,1]\n",
    "y_pred_LSVC = (y_pred_LSVC_predictions >= 0.5).astype(int)\n",
    "LinearSVC_acc = accuracy_score(y_test, y_pred_LSVC)\n",
    "LinearSVC_r2 = r2_score(y_test, y_pred_LSVC)\n",
    "LinearSVC_f1 = f1_score(y_test, y_pred_LSVC)\n",
    "print('LinearSVC Classifier classification report: \\n{}'.format(classification_report(y_test, y_pred_LSVC)))\n",
    "\n",
    "# 9. LGBM Classifier\n",
    "model = LGBMClassifier()\n",
    "model.fit(normalized_train_arr, y_train)\n",
    "\n",
    "y_pred_LGBM_predictions = model.predict_proba(normalized_test_arr)[:,1]\n",
    "y_pred_LGBM = (y_pred_LGBM_predictions >= 0.5).astype(int)\n",
    "LGBM_acc = accuracy_score(y_test, y_pred_LGBM)\n",
    "LGBM_r2 = r2_score(y_test, y_pred_LGBM)\n",
    "LGBM_f1 = f1_score(y_test, y_pred_LGBM)\n",
    "print('LGBM Classifier classification report: \\n{}'.format(classification_report(y_test, y_pred_LGBM)))\n",
    "\n",
    "# 10. Ансамбль из всех использованных классификаторов\n",
    "multi_model_ensemble_predictions = (\n",
    "    ydf_single_predictions + ydf_ensemble_predictions + y_pred_forest_predictions + \\\n",
    "    y_pred_logistic_predictions + y_pred_KNN_predictions + y_pred_SVC_predictions + \\\n",
    "    y_pred_LSVC_predictions + y_pred_XGB_predictions + y_pred_LGBM_predictions) / 9\n",
    "\n",
    "multi_model_ensemble = (multi_model_ensemble_predictions >= 0.5).astype(int)\n",
    "multi_model_ensemble_acc = accuracy_score(y_test, multi_model_ensemble)\n",
    "multi_model_ensemble_r2 = r2_score(y_test, multi_model_ensemble)\n",
    "multi_model_ensemble_f1 = f1_score(y_test, multi_model_ensemble)\n",
    "print('Multi model ensemble classification report: \\n{}'.format(classification_report(y_test, multi_model_ensemble)))\n",
    "\n",
    "leaderboard_acc = {\n",
    "    \"ydf GBT finetune\" : ydf_gbt_single_acc,\n",
    "    \"ydf GBT ensemble N={}\".format(ensemble_size) : ydf_gbt_ensemble_acc,\n",
    "    \"Random Forest\": forest_acc,\n",
    "    \"logistic regression\": logistic_acc,\n",
    "    \"XGB\": XGB_acc,\n",
    "    \"KNeighborsClassifier\": KNN_acc,\n",
    "    \"SVC\": SVC_acc,\n",
    "    \"Linear SVC\": LinearSVC_acc,\n",
    "    \"lightgbm\": LGBM_acc,\n",
    "    \"multi model ensemble\" : multi_model_ensemble_acc\n",
    "}\n",
    "\n",
    "leaderboard_F1 = {\n",
    "    \"ydf GBT finetune\" : ydf_gbt_single_f1,\n",
    "    \"ydf GBT ensemble N={}\".format(ensemble_size) : ydf_gbt_ensemble_f1,\n",
    "    \"Random Forest\": forest_f1,\n",
    "    \"logistic regression\": logistic_f1,\n",
    "    \"XGB\": XGB_f1,\n",
    "    \"KNeighborsClassifier\": KNN_f1,\n",
    "    \"SVC\": SVC_f1,\n",
    "    \"Linear SVC\": LinearSVC_f1,\n",
    "    \"lightgbm\": LGBM_f1,\n",
    "    \"multi model ensemble\" : multi_model_ensemble_f1\n",
    "}\n",
    "\n",
    "leaderboard_r2 = {\n",
    "    \"ydf GBT finetune\" : ydf_gbt_single_r2,\n",
    "    \"ydf GBT ensemble N={}\".format(ensemble_size) : ydf_gbt_ensemble_r2,\n",
    "    \"Random Forest\": forest_r2,\n",
    "    \"logistic regression\": logistic_r2,\n",
    "    \"XGB\": XGB_r2,\n",
    "    \"KNeighborsClassifier\": KNN_r2,\n",
    "    \"SVC\": SVC_r2,\n",
    "    \"Linear SVC\": LinearSVC_r2,\n",
    "    \"lightgbm\": LGBM_r2,\n",
    "    \"multi model ensemble\" : multi_model_ensemble_r2\n",
    "}\n",
    "\n",
    "# Сравним классификаторы по критериям точности, F1 и R2\n",
    "leaderboard_acc = dict(sorted(leaderboard_acc.items(), key=lambda item: item[1], reverse = True))\n",
    "leaderboard_acc = pd.DataFrame.from_dict(leaderboard_acc, orient='index', columns=['Accuracy'])\n",
    "print('\\n----------------------------------------------------------------------------')\n",
    "print(leaderboard_acc)\n",
    "\n",
    "leaderboard_r2 = dict(sorted(leaderboard_r2.items(), key=lambda item: item[1], reverse = True))\n",
    "leaderboard_r2 = pd.DataFrame.from_dict(leaderboard_r2, orient='index', columns=['R2'])\n",
    "print('\\n----------------------------------------------------------------------------')\n",
    "print(leaderboard_r2)\n",
    "\n",
    "leaderboard_F1 = dict(sorted(leaderboard_F1.items(), key=lambda item: item[1], reverse = True))\n",
    "leaderboard_F1 = pd.DataFrame.from_dict(leaderboard_F1, orient='index', columns=['F1'])\n",
    "print('\\n----------------------------------------------------------------------------')\n",
    "print(leaderboard_F1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование submission на kaggle для всех протестированных классификаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, r2_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Обучим все протестированные классификаторы на полных данных и сформируем submission на kaggle по каждому из них\n",
    "\n",
    "# Закодируем категориальные данные как числовые для классификаторов, которые не умеют работать с категориями\n",
    "# Получим список категориальных колонок\n",
    "s = (preprocessed_train_df.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "# Кодируем категориальные данные как числовые\n",
    "le = LabelEncoder()\n",
    "encoded_train = preprocessed_train_df.copy()\n",
    "encoded_val = preprocessed_val_df.copy()\n",
    "\n",
    "for column in object_cols:\n",
    "    print(f'Encoding categorical column {column}')\n",
    "    encoded_train[column] = le.fit_transform(encoded_train[column].values)\n",
    "    encoded_val[column] = le.fit_transform(encoded_val[column].values)\n",
    "\n",
    "raw_X_train = encoded_train[preprocessed_val_df.columns]\n",
    "y_train = encoded_train['Survived']\n",
    "\n",
    "# Нормируем признаки для улучшения сходимости обучения классификаторов\n",
    "# Также можно применять StandardScaler()\n",
    "sc_X = MinMaxScaler()\n",
    "cols = preprocessed_val_df.columns\n",
    "normalized_train_arr = sc_X.fit_transform(raw_X_train)\n",
    "normalized_val_arr = sc_X.transform(encoded_val[cols])\n",
    "\n",
    "# 1. ydf.GradientBoostedTrees с подобранными параметрами\n",
    "model = ydf.GradientBoostedTreesLearner(label=\"Survived\",\n",
    "                                        num_trees=100,\n",
    "                                        max_depth=6,\n",
    "                                        shrinkage=0.325,\n",
    "                                        subsample=0.9,\n",
    "                                        num_candidate_attributes_ratio=0.375).train(preprocessed_train_df)\n",
    "ydf_single_predictions = model.predict(preprocessed_val_df)\n",
    "sub_path = os.path.join(os.path.abspath(os.getcwd()), \"ydf_GBT_tuned.csv\")\n",
    "make_submission(prediction_to_kaggle_format(ydf_single_predictions), sub_path)\n",
    "\n",
    "# 2. Ансамбль из ydf.GradientBoostedTrees\n",
    "ydf_ensemble_predictions = None\n",
    "num_predictions = 0\n",
    "ensemble_size = 100\n",
    "for i in range(ensemble_size):\n",
    "    model = ydf.GradientBoostedTreesLearner(label=\"Survived\", honest=True, random_seed=i).train(preprocessed_train_df)\n",
    "    sub_predictions = model.predict(preprocessed_val_df)\n",
    "\n",
    "    if ydf_ensemble_predictions is None:\n",
    "        ydf_ensemble_predictions = sub_predictions\n",
    "    else:\n",
    "        ydf_ensemble_predictions += sub_predictions\n",
    "    num_predictions += 1\n",
    "\n",
    "ydf_ensemble_predictions /= num_predictions\n",
    "sub_path = os.path.join(os.path.abspath(os.getcwd()), \"ydf_GBT_ensemble_N_{}.csv\".format(ensemble_size))\n",
    "make_submission(prediction_to_kaggle_format(ydf_ensemble_predictions), sub_path)\n",
    "\n",
    "# 3. Логистическая регрессия\n",
    "pipeline = Pipeline([('logisticregression', LogisticRegression(max_iter=100))])\n",
    "param_grid = {'logisticregression__penalty' : ['l2'],\n",
    "              'logisticregression__C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'logisticregression__solver' : ['liblinear']}\n",
    "\n",
    "# GridSearchCV подбирает параметры модели\n",
    "model = GridSearchCV(pipeline, param_grid, cv =None)\n",
    "model.fit(normalized_train_arr, y_train)\n",
    "y_pred_logistic_predictions = model.predict_proba(normalized_val_arr)[:,1]\n",
    "sub_path = os.path.join(os.path.abspath(os.getcwd()), \"logistic_regression.csv\")\n",
    "make_submission(prediction_to_kaggle_format(y_pred_logistic_predictions), sub_path)\n",
    "\n",
    "\n",
    "# 4. RandomForestClassifier из пакета sklearn\n",
    "pipeline = Pipeline([('RandomForest', RandomForestClassifier())])\n",
    "param_grid = {\n",
    "  'RandomForest__min_samples_leaf': [1, 2, 4],\n",
    "  'RandomForest__min_samples_split': [2, 3, 4],\n",
    "  'RandomForest__n_estimators': [100, 200, 300]}\n",
    "\n",
    "model = GridSearchCV(pipeline, param_grid, cv =None)\n",
    "model.fit(normalized_train_arr, y_train)\n",
    "y_pred_forest_predictions = model.predict_proba(normalized_val_arr)[:,1]\n",
    "sub_path = os.path.join(os.path.abspath(os.getcwd()), \"RandomForestClassifier.csv\")\n",
    "make_submission(prediction_to_kaggle_format(y_pred_forest_predictions), sub_path)\n",
    "\n",
    "# 5. XGBClassifier\n",
    "model = XGBClassifier()\n",
    "model.fit(normalized_train_arr, y_train)\n",
    "y_pred_XGB_predictions = model.predict_proba(normalized_val_arr)[:,1]\n",
    "sub_path = os.path.join(os.path.abspath(os.getcwd()), \"XGB_Classifier.csv\")\n",
    "make_submission(prediction_to_kaggle_format(y_pred_XGB_predictions), sub_path)\n",
    "\n",
    "# 6. KNN classifier\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(normalized_train_arr, y_train)\n",
    "y_pred_KNN_predictions = model.predict_proba(normalized_val_arr)[:,1]\n",
    "sub_path = os.path.join(os.path.abspath(os.getcwd()), \"KNN_Classifier.csv\")\n",
    "make_submission(prediction_to_kaggle_format(y_pred_KNN_predictions), sub_path)\n",
    "\n",
    "# 7. SVM (SVC) classifier, rbf kernel\n",
    "model = SVC(probability=True)\n",
    "model.fit(normalized_train_arr, y_train)\n",
    "y_pred_SVC_predictions = model.predict_proba(normalized_val_arr)[:,1]\n",
    "sub_path = os.path.join(os.path.abspath(os.getcwd()), \"SVC_RBF_Classifier.csv\")\n",
    "make_submission(prediction_to_kaggle_format(y_pred_SVC_predictions), sub_path)\n",
    "\n",
    "# 8. SVM (LinearSVC) classifier\n",
    "model = SVC(kernel='linear',probability=True)\n",
    "model.fit(normalized_train_arr, y_train)\n",
    "y_pred_LSVC_predictions = model.predict_proba(normalized_val_arr)[:,1]\n",
    "sub_path = os.path.join(os.path.abspath(os.getcwd()), \"LinearSVC_Classifier.csv\")\n",
    "make_submission(prediction_to_kaggle_format(y_pred_LSVC_predictions), sub_path)\n",
    "\n",
    "# 9. LGBM Classifier\n",
    "model = LGBMClassifier()\n",
    "model.fit(normalized_train_arr, y_train)\n",
    "y_pred_LGBM_predictions = model.predict_proba(normalized_val_arr)[:,1]\n",
    "sub_path = os.path.join(os.path.abspath(os.getcwd()), \"LGBM_Classifier.csv\")\n",
    "make_submission(prediction_to_kaggle_format(y_pred_LGBM_predictions), sub_path)\n",
    "\n",
    "# 10. Ансамбль из всех использованных классификаторов\n",
    "multi_model_ensemble_predictions = (\n",
    "    ydf_single_predictions + ydf_ensemble_predictions + y_pred_forest_predictions + \\\n",
    "    y_pred_logistic_predictions + y_pred_KNN_predictions + y_pred_SVC_predictions + \\\n",
    "    y_pred_LSVC_predictions + y_pred_XGB_predictions + y_pred_LGBM_predictions) / 9\n",
    "\n",
    "sub_path = os.path.join(os.path.abspath(os.getcwd()), \"multi_model_ensemble.csv\")\n",
    "make_submission(prediction_to_kaggle_format(multi_model_ensemble_predictions), sub_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
